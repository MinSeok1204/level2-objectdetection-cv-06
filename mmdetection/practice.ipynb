{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.platform: linux\n",
      "Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "CUDA available: True\n",
      "numpy_random_seed: 42\n",
      "GPU 0: Tesla V100-SXM2-32GB\n",
      "CUDA_HOME: None\n",
      "GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "PyTorch: 1.12.1+cu116\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.6\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.13.1+cu116\n",
      "OpenCV: 4.8.1\n",
      "MMEngine: 0.10.1\n",
      "MMDetection: 3.3.0+83f7f51\n"
     ]
    }
   ],
   "source": [
    "from mmengine.utils import get_git_hash\n",
    "from mmengine.utils.dl_utils import collect_env as collect_base_env\n",
    "\n",
    "import mmdet\n",
    "\n",
    "\n",
    "def collect_env():\n",
    "    \"\"\"Collect the information of the running environments.\"\"\"\n",
    "    env_info = collect_base_env()\n",
    "    env_info['MMDetection'] = f'{mmdet.__version__}+{get_git_hash()[:7]}'\n",
    "    return env_info\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for name, val in collect_env().items():\n",
    "        print(f'{name}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "Category ID: 0, Category Name: General trash\n",
      "Category ID: 1, Category Name: Paper\n",
      "Category ID: 2, Category Name: Paper pack\n",
      "Category ID: 3, Category Name: Metal\n",
      "Category ID: 4, Category Name: Glass\n",
      "Category ID: 5, Category Name: Plastic\n",
      "Category ID: 6, Category Name: Styrofoam\n",
      "Category ID: 7, Category Name: Plastic bag\n",
      "Category ID: 8, Category Name: Battery\n",
      "Category ID: 9, Category Name: Clothing\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Path to load the COCO annotation file\n",
    "annotation_file = '../dataset/json/train.json'\n",
    "\n",
    "# Initialise the COCO object\n",
    "coco = COCO(annotation_file)\n",
    "\n",
    "# Get all category tags and corresponding category IDs\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "category_id_to_name = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "# Print all category IDs and corresponding category names\n",
    "for category_id, category_name in category_id_to_name.items():\n",
    "    print(f\"Category ID: {category_id}, Category Name: {category_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_scale_lr = dict(base_batch_size=16)\n",
      "backend_args = None\n",
      "batch_augments = [\n",
      "    dict(pad_mask=False, size=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='BatchFixedSizePad'),\n",
      "]\n",
      "custom_imports = dict(\n",
      "    allow_failed_imports=False, imports=[\n",
      "        'projects.CO-DETR.codetr',\n",
      "    ])\n",
      "data_root = 'data/coco/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        _scope_='mmdet',\n",
      "        by_epoch=True,\n",
      "        interval=1,\n",
      "        max_keep_ckpts=3,\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(_scope_='mmdet', interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(_scope_='mmdet', type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(_scope_='mmdet', type='DistSamplerSeedHook'),\n",
      "    timer=dict(_scope_='mmdet', type='IterTimerHook'),\n",
      "    visualization=dict(_scope_='mmdet', type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "image_size = (\n",
      "    1024,\n",
      "    1024,\n",
      ")\n",
      "load_from = None\n",
      "load_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.1,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            1024,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(\n",
      "        allow_negative_crop=True,\n",
      "        crop_size=(\n",
      "            1024,\n",
      "            1024,\n",
      "        ),\n",
      "        crop_type='absolute_range',\n",
      "        recompute_bbox=True,\n",
      "        type='RandomCrop'),\n",
      "    dict(min_gt_bbox_wh=(\n",
      "        0.01,\n",
      "        0.01,\n",
      "    ), type='FilterAnnotations'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Pad'),\n",
      "]\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(\n",
      "    _scope_='mmdet', by_epoch=True, type='LogProcessor', window_size=50)\n",
      "loss_lambda = 2.0\n",
      "max_epochs = 12\n",
      "max_iters = 270000\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        frozen_stages=1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=False, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    bbox_head=[\n",
      "        dict(\n",
      "            anchor_generator=dict(\n",
      "                octave_base_scale=8,\n",
      "                ratios=[\n",
      "                    1.0,\n",
      "                ],\n",
      "                scales_per_octave=1,\n",
      "                strides=[\n",
      "                    4,\n",
      "                    8,\n",
      "                    16,\n",
      "                    32,\n",
      "                    64,\n",
      "                    128,\n",
      "                ],\n",
      "                type='AnchorGenerator'),\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            feat_channels=256,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=24.0, type='GIoULoss'),\n",
      "            loss_centerness=dict(\n",
      "                loss_weight=12.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "            loss_cls=dict(\n",
      "                alpha=0.25,\n",
      "                gamma=2.0,\n",
      "                loss_weight=12.0,\n",
      "                type='FocalLoss',\n",
      "                use_sigmoid=True),\n",
      "            num_classes=80,\n",
      "            stacked_convs=1,\n",
      "            type='CoATSSHead'),\n",
      "    ],\n",
      "    data_preprocessor=dict(\n",
      "        batch_augments=[\n",
      "            dict(\n",
      "                pad_mask=False, size=(\n",
      "                    1024,\n",
      "                    1024,\n",
      "                ), type='BatchFixedSizePad'),\n",
      "        ],\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_mask=False,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    eval_module='detr',\n",
      "    neck=dict(\n",
      "        act_cfg=None,\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        kernel_size=1,\n",
      "        norm_cfg=dict(num_groups=32, type='GN'),\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='ChannelMapper'),\n",
      "    query_head=dict(\n",
      "        as_two_stage=True,\n",
      "        dn_cfg=dict(\n",
      "            box_noise_scale=1.0,\n",
      "            group_cfg=dict(dynamic=True, num_dn_queries=100, num_groups=None),\n",
      "            label_noise_scale=0.5),\n",
      "        in_channels=2048,\n",
      "        loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0,\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "        num_classes=80,\n",
      "        num_query=900,\n",
      "        positional_encoding=dict(\n",
      "            normalize=True,\n",
      "            num_feats=128,\n",
      "            temperature=20,\n",
      "            type='SinePositionalEncoding'),\n",
      "        transformer=dict(\n",
      "            decoder=dict(\n",
      "                num_layers=6,\n",
      "                return_intermediate=True,\n",
      "                transformerlayers=dict(\n",
      "                    attn_cfgs=[\n",
      "                        dict(\n",
      "                            dropout=0.0,\n",
      "                            embed_dims=256,\n",
      "                            num_heads=8,\n",
      "                            type='MultiheadAttention'),\n",
      "                        dict(\n",
      "                            dropout=0.0,\n",
      "                            embed_dims=256,\n",
      "                            num_levels=5,\n",
      "                            type='MultiScaleDeformableAttention'),\n",
      "                    ],\n",
      "                    feedforward_channels=2048,\n",
      "                    ffn_dropout=0.0,\n",
      "                    operation_order=(\n",
      "                        'self_attn',\n",
      "                        'norm',\n",
      "                        'cross_attn',\n",
      "                        'norm',\n",
      "                        'ffn',\n",
      "                        'norm',\n",
      "                    ),\n",
      "                    type='DetrTransformerDecoderLayer'),\n",
      "                type='DinoTransformerDecoder'),\n",
      "            encoder=dict(\n",
      "                num_layers=6,\n",
      "                transformerlayers=dict(\n",
      "                    attn_cfgs=dict(\n",
      "                        dropout=0.0,\n",
      "                        embed_dims=256,\n",
      "                        num_levels=5,\n",
      "                        type='MultiScaleDeformableAttention'),\n",
      "                    feedforward_channels=2048,\n",
      "                    ffn_dropout=0.0,\n",
      "                    operation_order=(\n",
      "                        'self_attn',\n",
      "                        'norm',\n",
      "                        'ffn',\n",
      "                        'norm',\n",
      "                    ),\n",
      "                    type='BaseTransformerLayer'),\n",
      "                type='DetrTransformerEncoder',\n",
      "                with_cp=4),\n",
      "            num_co_heads=2,\n",
      "            num_feature_levels=5,\n",
      "            type='CoDinoTransformer',\n",
      "            with_coord_feat=False),\n",
      "        type='CoDINOHead'),\n",
      "    roi_head=[\n",
      "        dict(\n",
      "            bbox_head=dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=120.0, type='GIoULoss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=12.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=80,\n",
      "                reg_class_agnostic=False,\n",
      "                reg_decoded_bbox=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            bbox_roi_extractor=dict(\n",
      "                featmap_strides=[\n",
      "                    4,\n",
      "                    8,\n",
      "                    16,\n",
      "                    32,\n",
      "                    64,\n",
      "                ],\n",
      "                finest_scale=56,\n",
      "                out_channels=256,\n",
      "                roi_layer=dict(\n",
      "                    output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "                type='SingleRoIExtractor'),\n",
      "            type='CoStandardRoIHead'),\n",
      "    ],\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            octave_base_scale=4,\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales_per_octave=3,\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "                128,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=12.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=12.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=[\n",
      "        dict(max_per_img=300, nms=dict(iou_threshold=0.8, type='soft_nms')),\n",
      "        dict(\n",
      "            rcnn=dict(\n",
      "                max_per_img=100,\n",
      "                nms=dict(iou_threshold=0.5, type='nms'),\n",
      "                score_thr=0.0),\n",
      "            rpn=dict(\n",
      "                max_per_img=1000,\n",
      "                min_bbox_size=0,\n",
      "                nms=dict(iou_threshold=0.7, type='nms'),\n",
      "                nms_pre=1000)),\n",
      "        dict(\n",
      "            max_per_img=100,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=1000,\n",
      "            score_thr=0.0),\n",
      "    ],\n",
      "    train_cfg=[\n",
      "        dict(\n",
      "            assigner=dict(\n",
      "                match_costs=[\n",
      "                    dict(type='FocalLossCost', weight=2.0),\n",
      "                    dict(box_format='xywh', type='BBoxL1Cost', weight=5.0),\n",
      "                    dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                ],\n",
      "                type='HungarianAssigner')),\n",
      "        dict(\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            rpn=dict(\n",
      "                allowed_border=-1,\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=True,\n",
      "                    min_pos_iou=0.3,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=False,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    type='RandomSampler')),\n",
      "            rpn_proposal=dict(\n",
      "                max_per_img=1000,\n",
      "                min_bbox_size=0,\n",
      "                nms=dict(iou_threshold=0.7, type='nms'),\n",
      "                nms_pre=4000)),\n",
      "        dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(topk=9, type='ATSSAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1),\n",
      "    ],\n",
      "    type='CoDETR',\n",
      "    use_lsj=True)\n",
      "num_classes = 80\n",
      "num_dec_layer = 6\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=0.1, norm_type=2),\n",
      "    optimizer=dict(lr=0.0002, type='AdamW', weight_decay=0.0001),\n",
      "    paramwise_cfg=dict(custom_keys=dict(backbone=dict(lr_mult=0.1))),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=12,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            11,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(_scope_='mmdet', type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        _scope_='mmdet',\n",
      "        ann_file='annotations/instances_val2017.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2017/'),\n",
      "        data_root='data/coco/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    1024,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(_scope_='mmdet', shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    _scope_='mmdet',\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Pad'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        _scope_='mmdet',\n",
      "        dataset=dict(\n",
      "            ann_file='annotations/instances_train2017.json',\n",
      "            backend_args=None,\n",
      "            data_prefix=dict(img='train2017/'),\n",
      "            data_root='data/coco/',\n",
      "            filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
      "            pipeline=[\n",
      "                dict(type='LoadImageFromFile'),\n",
      "                dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    ratio_range=(\n",
      "                        0.1,\n",
      "                        2.0,\n",
      "                    ),\n",
      "                    scale=(\n",
      "                        1024,\n",
      "                        1024,\n",
      "                    ),\n",
      "                    type='RandomResize'),\n",
      "                dict(\n",
      "                    allow_negative_crop=True,\n",
      "                    crop_size=(\n",
      "                        1024,\n",
      "                        1024,\n",
      "                    ),\n",
      "                    crop_type='absolute_range',\n",
      "                    recompute_bbox=True,\n",
      "                    type='RandomCrop'),\n",
      "                dict(min_gt_bbox_wh=(\n",
      "                    0.01,\n",
      "                    0.01,\n",
      "                ), type='FilterAnnotations'),\n",
      "                dict(prob=0.5, type='RandomFlip'),\n",
      "                dict(\n",
      "                    pad_val=dict(img=(\n",
      "                        114,\n",
      "                        114,\n",
      "                        114,\n",
      "                    )),\n",
      "                    size=(\n",
      "                        1024,\n",
      "                        1024,\n",
      "                    ),\n",
      "                    type='Pad'),\n",
      "            ],\n",
      "            type='CocoDataset'),\n",
      "        pipeline=[\n",
      "            dict(max_num_pasted=100, paste_by_box=True, type='CopyPaste'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='MultiImageMixDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(_scope_='mmdet', shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(max_num_pasted=100, paste_by_box=True, type='CopyPaste'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(_scope_='mmdet', type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        _scope_='mmdet',\n",
      "        ann_file='annotations/instances_val2017.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val2017/'),\n",
      "        data_root='data/coco/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    1024,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(_scope_='mmdet', shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    _scope_='mmdet',\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(_scope_='mmdet', type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    _scope_='mmdet',\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('./projects/CO-DETR/configs/codino/co_dino_5scale_r50_lsj_8xb2_1x_coco_nomask.py')\n",
    "# cfg = Config.fromfile('./co_dino_5scale_r50_lsj_8xb2_1x_trash.py')\n",
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.runner import set_random_seed\n",
    "\n",
    "# pre-training weight paths\n",
    "cfg.load_from = './checkpoints/co_dino_5scale_r50_lsj_8xb2_1x_coco-69a72d67.pth'\n",
    "\n",
    "# batch size\n",
    "cfg.train_dataloader.batch_size = 1\n",
    "# dataloader num workers\n",
    "cfg.train_dataloader.num_workers = 8\n",
    "\n",
    "# freezing the layers of the backbone network\n",
    "cfg.model.backbone.frozen_stages = -1\n",
    "# number of classifications\n",
    "cfg.num_classes = 10\n",
    "\n",
    "# For single card training, you need to change SyncBN to BN\n",
    "#cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "# labels and palettes(very important!!)\n",
    "cfg.metainfo = {\n",
    "    'classes': (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\",\n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "}\n",
    "\n",
    "# data folder\n",
    "cfg.data_root = '../dataset'\n",
    "\n",
    "# train json file path\n",
    "cfg.train_dataloader.dataset.dataset.ann_file = 'json/splits/train_fold4.json'\n",
    "cfg.train_dataloader.dataset.dataset.data_root = cfg.data_root\n",
    "# train image file path\n",
    "cfg.train_dataloader.dataset.dataset.data_prefix.img = ''\n",
    "cfg.train_dataloader.dataset.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "# valid json file path\n",
    "cfg.val_dataloader.dataset.ann_file = 'json/splits/val_fold4.json'\n",
    "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
    "# valid image file path\n",
    "cfg.val_dataloader.dataset.data_prefix.img = ''\n",
    "cfg.val_dataloader.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "\n",
    "cfg.test_dataloader = cfg.val_dataloader\n",
    "\n",
    "# valid evaluator json file path\n",
    "cfg.val_evaluator.ann_file = cfg.data_root+'/'+'json/splits/val_fold4.json'\n",
    "\n",
    "cfg.test_evaluator = cfg.val_evaluator\n",
    "\n",
    "# ⭐️ Set the checkpoint interval.\n",
    "cfg.default_hooks.checkpoint.interval = 4\n",
    "\n",
    "cfg.device = 'cuda'\n",
    "\n",
    "# ⭐️ Set the evaluation interval.\n",
    "#cfg.evaluation.interval = 2\n",
    "\n",
    "\n",
    "# model weights are saved every 10 intervals, up to two weights are saved at the same time, and the saving strategy is auto\n",
    "#cfg.default_hooks.checkpoint = dict(type='CheckpointHook', interval=10, max_keep_ckpts=2, save_best='auto')\n",
    "# Interval of reporting indicators\n",
    "#cfg.default_hooks.logger.interval = 1\n",
    "\n",
    "# the ballon dataset is small, so each epoch repeats the data 4 times\n",
    "#cfg.train_dataloader.dataset = dict(dict(type='RepeatDataset',times=4,dataset=cfg.train_dataloader.dataset.dataset))\n",
    "\n",
    "# Fixed random number seed\n",
    "set_random_seed(42, deterministic=False)\n",
    "\n",
    "cfg.visualizer.vis_backends= [\n",
    "    dict(type='LocalVisBackend'),\n",
    "    dict(type='WandbVisBackend'),\n",
    "]\n",
    "\n",
    "\n",
    "#------------------------------------------------------\n",
    "config=f'./custom_configs/co_dino_5scale_r50_lsj_8xb2_1x_trash.py'\n",
    "with open(config, 'w') as f:\n",
    "    f.write(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/15 13:58:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 538036752\n",
      "    GPU 0: Tesla V100-SXM2-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 1.12.1+cu116\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.6\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.1+cu116\n",
      "    OpenCV: 4.8.1\n",
      "    MMEngine: 0.10.1\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 538036752\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "10/15 13:58:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16)\n",
      "backend_args = None\n",
      "batch_augments = [\n",
      "    dict(pad_mask=True, size=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='BatchFixedSizePad'),\n",
      "]\n",
      "custom_imports = dict(\n",
      "    allow_failed_imports=False, imports=[\n",
      "        'projects.CO-DETR.codetr',\n",
      "    ])\n",
      "data_root = '../dataset/splits'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        _scope_='mmdet',\n",
      "        by_epoch=True,\n",
      "        interval=4,\n",
      "        max_keep_ckpts=3,\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(_scope_='mmdet', interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(_scope_='mmdet', type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(_scope_='mmdet', type='DistSamplerSeedHook'),\n",
      "    timer=dict(_scope_='mmdet', type='IterTimerHook'),\n",
      "    visualization=dict(_scope_='mmdet', type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "device = 'cuda'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "image_size = (\n",
      "    1024,\n",
      "    1024,\n",
      ")\n",
      "launcher = 'none'\n",
      "load_from = './checkpoints/co_dino_5scale_r50_lsj_8xb2_1x_coco-69a72d67.pth'\n",
      "load_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.1,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            1024,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(\n",
      "        allow_negative_crop=True,\n",
      "        crop_size=(\n",
      "            1024,\n",
      "            1024,\n",
      "        ),\n",
      "        crop_type='absolute_range',\n",
      "        recompute_bbox=True,\n",
      "        type='RandomCrop'),\n",
      "    dict(min_gt_bbox_wh=(\n",
      "        0.01,\n",
      "        0.01,\n",
      "    ), type='FilterAnnotations'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Pad'),\n",
      "]\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(\n",
      "    _scope_='mmdet', by_epoch=True, type='LogProcessor', window_size=50)\n",
      "loss_lambda = 2.0\n",
      "max_epochs = 12\n",
      "max_iters = 270000\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'General trash',\n",
      "        'Paper',\n",
      "        'Paper pack',\n",
      "        'Metal',\n",
      "        'Glass',\n",
      "        'Plastic',\n",
      "        'Styrofoam',\n",
      "        'Plastic bag',\n",
      "        'Battery',\n",
      "        'Clothing',\n",
      "    ))\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        frozen_stages=-1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=False, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    bbox_head=[\n",
      "        dict(\n",
      "            anchor_generator=dict(\n",
      "                octave_base_scale=8,\n",
      "                ratios=[\n",
      "                    1.0,\n",
      "                ],\n",
      "                scales_per_octave=1,\n",
      "                strides=[\n",
      "                    4,\n",
      "                    8,\n",
      "                    16,\n",
      "                    32,\n",
      "                    64,\n",
      "                    128,\n",
      "                ],\n",
      "                type='AnchorGenerator'),\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            feat_channels=256,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=24.0, type='GIoULoss'),\n",
      "            loss_centerness=dict(\n",
      "                loss_weight=12.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "            loss_cls=dict(\n",
      "                alpha=0.25,\n",
      "                gamma=2.0,\n",
      "                loss_weight=12.0,\n",
      "                type='FocalLoss',\n",
      "                use_sigmoid=True),\n",
      "            num_classes=80,\n",
      "            stacked_convs=1,\n",
      "            type='CoATSSHead'),\n",
      "    ],\n",
      "    data_preprocessor=dict(\n",
      "        batch_augments=[\n",
      "            dict(pad_mask=True, size=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='BatchFixedSizePad'),\n",
      "        ],\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_mask=True,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    eval_module='detr',\n",
      "    neck=dict(\n",
      "        act_cfg=None,\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        kernel_size=1,\n",
      "        norm_cfg=dict(num_groups=32, type='GN'),\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='ChannelMapper'),\n",
      "    query_head=dict(\n",
      "        as_two_stage=True,\n",
      "        dn_cfg=dict(\n",
      "            box_noise_scale=1.0,\n",
      "            group_cfg=dict(dynamic=True, num_dn_queries=100, num_groups=None),\n",
      "            label_noise_scale=0.5),\n",
      "        in_channels=2048,\n",
      "        loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0,\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "        num_classes=80,\n",
      "        num_query=900,\n",
      "        positional_encoding=dict(\n",
      "            normalize=True,\n",
      "            num_feats=128,\n",
      "            temperature=20,\n",
      "            type='SinePositionalEncoding'),\n",
      "        transformer=dict(\n",
      "            decoder=dict(\n",
      "                num_layers=6,\n",
      "                return_intermediate=True,\n",
      "                transformerlayers=dict(\n",
      "                    attn_cfgs=[\n",
      "                        dict(\n",
      "                            dropout=0.0,\n",
      "                            embed_dims=256,\n",
      "                            num_heads=8,\n",
      "                            type='MultiheadAttention'),\n",
      "                        dict(\n",
      "                            dropout=0.0,\n",
      "                            embed_dims=256,\n",
      "                            num_levels=5,\n",
      "                            type='MultiScaleDeformableAttention'),\n",
      "                    ],\n",
      "                    feedforward_channels=2048,\n",
      "                    ffn_dropout=0.0,\n",
      "                    operation_order=(\n",
      "                        'self_attn',\n",
      "                        'norm',\n",
      "                        'cross_attn',\n",
      "                        'norm',\n",
      "                        'ffn',\n",
      "                        'norm',\n",
      "                    ),\n",
      "                    type='DetrTransformerDecoderLayer'),\n",
      "                type='DinoTransformerDecoder'),\n",
      "            encoder=dict(\n",
      "                num_layers=6,\n",
      "                transformerlayers=dict(\n",
      "                    attn_cfgs=dict(\n",
      "                        dropout=0.0,\n",
      "                        embed_dims=256,\n",
      "                        num_levels=5,\n",
      "                        type='MultiScaleDeformableAttention'),\n",
      "                    feedforward_channels=2048,\n",
      "                    ffn_dropout=0.0,\n",
      "                    operation_order=(\n",
      "                        'self_attn',\n",
      "                        'norm',\n",
      "                        'ffn',\n",
      "                        'norm',\n",
      "                    ),\n",
      "                    type='BaseTransformerLayer'),\n",
      "                type='DetrTransformerEncoder',\n",
      "                with_cp=4),\n",
      "            num_co_heads=2,\n",
      "            num_feature_levels=5,\n",
      "            type='CoDinoTransformer',\n",
      "            with_coord_feat=False),\n",
      "        type='CoDINOHead'),\n",
      "    roi_head=[\n",
      "        dict(\n",
      "            bbox_head=dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(loss_weight=120.0, type='GIoULoss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=12.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=80,\n",
      "                reg_class_agnostic=False,\n",
      "                reg_decoded_bbox=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            bbox_roi_extractor=dict(\n",
      "                featmap_strides=[\n",
      "                    4,\n",
      "                    8,\n",
      "                    16,\n",
      "                    32,\n",
      "                    64,\n",
      "                ],\n",
      "                finest_scale=56,\n",
      "                out_channels=256,\n",
      "                roi_layer=dict(\n",
      "                    output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "                type='SingleRoIExtractor'),\n",
      "            type='CoStandardRoIHead'),\n",
      "    ],\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            octave_base_scale=4,\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales_per_octave=3,\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "                128,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=12.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=12.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=[\n",
      "        dict(max_per_img=300, nms=dict(iou_threshold=0.8, type='soft_nms')),\n",
      "        dict(\n",
      "            rcnn=dict(\n",
      "                max_per_img=100,\n",
      "                nms=dict(iou_threshold=0.5, type='nms'),\n",
      "                score_thr=0.0),\n",
      "            rpn=dict(\n",
      "                max_per_img=1000,\n",
      "                min_bbox_size=0,\n",
      "                nms=dict(iou_threshold=0.7, type='nms'),\n",
      "                nms_pre=1000)),\n",
      "        dict(\n",
      "            max_per_img=100,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.6, type='nms'),\n",
      "            nms_pre=1000,\n",
      "            score_thr=0.0),\n",
      "    ],\n",
      "    train_cfg=[\n",
      "        dict(\n",
      "            assigner=dict(\n",
      "                match_costs=[\n",
      "                    dict(type='FocalLossCost', weight=2.0),\n",
      "                    dict(box_format='xywh', type='BBoxL1Cost', weight=5.0),\n",
      "                    dict(iou_mode='giou', type='IoUCost', weight=2.0),\n",
      "                ],\n",
      "                type='HungarianAssigner')),\n",
      "        dict(\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            rpn=dict(\n",
      "                allowed_border=-1,\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=True,\n",
      "                    min_pos_iou=0.3,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=False,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    type='RandomSampler')),\n",
      "            rpn_proposal=dict(\n",
      "                max_per_img=1000,\n",
      "                min_bbox_size=0,\n",
      "                nms=dict(iou_threshold=0.7, type='nms'),\n",
      "                nms_pre=4000)),\n",
      "        dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(topk=9, type='ATSSAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1),\n",
      "    ],\n",
      "    type='CoDETR',\n",
      "    use_lsj=True)\n",
      "num_classes = 10\n",
      "num_dec_layer = 6\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=0.1, norm_type=2),\n",
      "    optimizer=dict(lr=0.0002, type='AdamW', weight_decay=0.0001),\n",
      "    paramwise_cfg=dict(custom_keys=dict(backbone=dict(lr_mult=0.1))),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=12,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            11,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(_scope_='mmdet', type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        _scope_='mmdet',\n",
      "        ann_file='val_fold4.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='../dataset/splits',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    1024,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(_scope_='mmdet', shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    _scope_='mmdet',\n",
      "    ann_file='../dataset/splits/val_fold4.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Pad'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        _scope_='mmdet',\n",
      "        dataset=dict(\n",
      "            ann_file='train_fold4.json',\n",
      "            backend_args=None,\n",
      "            data_prefix=dict(img=''),\n",
      "            data_root='../dataset/splits',\n",
      "            filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
      "            metainfo=dict(\n",
      "                classes=(\n",
      "                    'General trash',\n",
      "                    'Paper',\n",
      "                    'Paper pack',\n",
      "                    'Metal',\n",
      "                    'Glass',\n",
      "                    'Plastic',\n",
      "                    'Styrofoam',\n",
      "                    'Plastic bag',\n",
      "                    'Battery',\n",
      "                    'Clothing',\n",
      "                )),\n",
      "            pipeline=[\n",
      "                dict(type='LoadImageFromFile'),\n",
      "                dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    ratio_range=(\n",
      "                        0.1,\n",
      "                        2.0,\n",
      "                    ),\n",
      "                    scale=(\n",
      "                        1024,\n",
      "                        1024,\n",
      "                    ),\n",
      "                    type='RandomResize'),\n",
      "                dict(\n",
      "                    allow_negative_crop=True,\n",
      "                    crop_size=(\n",
      "                        1024,\n",
      "                        1024,\n",
      "                    ),\n",
      "                    crop_type='absolute_range',\n",
      "                    recompute_bbox=True,\n",
      "                    type='RandomCrop'),\n",
      "                dict(min_gt_bbox_wh=(\n",
      "                    0.01,\n",
      "                    0.01,\n",
      "                ), type='FilterAnnotations'),\n",
      "                dict(prob=0.5, type='RandomFlip'),\n",
      "                dict(\n",
      "                    pad_val=dict(img=(\n",
      "                        114,\n",
      "                        114,\n",
      "                        114,\n",
      "                    )),\n",
      "                    size=(\n",
      "                        1024,\n",
      "                        1024,\n",
      "                    ),\n",
      "                    type='Pad'),\n",
      "            ],\n",
      "            type='CocoDataset'),\n",
      "        pipeline=[\n",
      "            dict(max_num_pasted=100, type='CopyPaste'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='MultiImageMixDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(_scope_='mmdet', shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(max_num_pasted=100, type='CopyPaste'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(_scope_='mmdet', type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        _scope_='mmdet',\n",
      "        ann_file='val_fold4.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='../dataset/splits',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    1024,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(_scope_='mmdet', shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    _scope_='mmdet',\n",
      "    ann_file='../dataset/splits/val_fold4.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(_scope_='mmdet', type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    _scope_='mmdet',\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='WandbVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/co_dino_5scale_r50_lsj_8xb2_1x_trash'\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/data/ephemeral/home/jaehuni/level2-objectdetection-cv-06/mmdetection/work_dirs/co_dino_5scale_r50_lsj_8xb2_1x_trash/20241015_135823/vis_data/wandb/run-20241015_135831-vml7gefa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdark-night-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/CV_06/level2-objectdetection-cv-06-mmdetection_tools\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/CV_06/level2-objectdetection-cv-06-mmdetection_tools/runs/vml7gefa\u001b[0m\n",
      "/data/ephemeral/home/jaehuni/level2-objectdetection-cv-06/mmdetection/projects/CO-DETR/codetr/transformer.py:1325: UserWarning: If you want to reduce GPU memory usage,                               please install fairscale by executing the                               following command: pip install fairscale.\n",
      "  warnings.warn('If you want to reduce GPU memory usage, \\\n",
      "/opt/conda/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:108: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "10/15 13:58:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "10/15 13:58:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/ephemeral/home/jaehuni/level2-objectdetection-cv-06/mmdetection/./tools/train.py\", line 124, in <module>\n",
      "    main()\n",
      "  File \"/data/ephemeral/home/jaehuni/level2-objectdetection-cv-06/mmdetection/./tools/train.py\", line 120, in main\n",
      "    runner.train()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py\", line 1728, in train\n",
      "    self._train_loop = self.build_train_loop(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py\", line 1520, in build_train_loop\n",
      "    loop = LOOPS.build(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/registry/registry.py\", line 570, in build\n",
      "    return self.build_func(cfg, *args, **kwargs, registry=self)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/registry/build_functions.py\", line 121, in build_from_cfg\n",
      "    obj = obj_cls(**args)  # type: ignore\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/runner/loops.py\", line 44, in __init__\n",
      "    super().__init__(runner, dataloader)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/runner/base_loop.py\", line 26, in __init__\n",
      "    self.dataloader = runner.build_dataloader(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py\", line 1370, in build_dataloader\n",
      "    dataset = DATASETS.build(dataset_cfg)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/registry/registry.py\", line 570, in build\n",
      "    return self.build_func(cfg, *args, **kwargs, registry=self)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/registry/build_functions.py\", line 121, in build_from_cfg\n",
      "    obj = obj_cls(**args)  # type: ignore\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmdet/datasets/dataset_wrappers.py\", line 64, in __init__\n",
      "    self.dataset = DATASETS.build(dataset)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/registry/registry.py\", line 570, in build\n",
      "    return self.build_func(cfg, *args, **kwargs, registry=self)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/registry/build_functions.py\", line 121, in build_from_cfg\n",
      "    obj = obj_cls(**args)  # type: ignore\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmdet/datasets/base_det_dataset.py\", line 51, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmengine/dataset/base_dataset.py\", line 247, in __init__\n",
      "    self.full_init()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmdet/datasets/base_det_dataset.py\", line 76, in full_init\n",
      "    self.data_list = self.load_data_list()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmdet/datasets/coco.py\", line 67, in load_data_list\n",
      "    self.coco = self.COCOAPI(local_path)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/mmdet/datasets/api_wrappers/coco_api.py\", line 25, in __init__\n",
      "    super().__init__(annotation_file=annotation_file)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pycocotools/coco.py\", line 81, in __init__\n",
      "    with open(annotation_file, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../dataset/splits/train_fold4.json'\n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mdark-night-1\u001b[0m at: \u001b[34mhttps://wandb.ai/CV_06/level2-objectdetection-cv-06-mmdetection_tools/runs/vml7gefa\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwork_dirs/co_dino_5scale_r50_lsj_8xb2_1x_trash/20241015_135823/vis_data/wandb/run-20241015_135831-vml7gefa/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/train.py {config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "# 모델 초기화\n",
    "epoch = 20\n",
    "config_file = './cascade-rcnn_x101_64x4d_fpn_20e_trash.py'  # 모델 설정 파일 경로\n",
    "checkpoint_file = f'./work_dirs/cascade-rcnn_x101_64x4d_fpn_20e_trash/epoch_{epoch}.pth'  # 체크포인트 파일 경로\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "# 이미지 경로 및 결과 저장 경로 설정\n",
    "image_folder = '../../dataset/test'  # 이미지 폴더 경로\n",
    "output_csv = './output/cascade-rcnn_output_predictions.csv'  # 출력 CSV 파일 경로\n",
    "\n",
    "# 결과 저장 리스트\n",
    "results = []\n",
    "\n",
    "# 이미지 추론\n",
    "for image_name in os.listdir(image_folder):\n",
    "    if image_name.endswith(('.jpg', '.png')):  # 지원되는 이미지 형식 확인\n",
    "        img_path = os.path.join(image_folder, image_name)\n",
    "        result = inference_detector(model, img_path)\n",
    "\n",
    "        # DetDataSample에서 결과 추출\n",
    "        prediction_string = []\n",
    "        if hasattr(result, 'pred_instances'):\n",
    "            det_samples = result.pred_instances  # 예측 결과의 인스턴스들\n",
    "            if det_samples is not None:\n",
    "                bboxes = det_samples.bboxes\n",
    "                scores = det_samples.scores\n",
    "                labels = det_samples.labels\n",
    "\n",
    "                for j in range(len(bboxes)):\n",
    "                    prediction_string.append(\n",
    "                        f\"{int(labels[j])} {scores[j]:.4f} {bboxes[j][0]:.2f} {bboxes[j][1]:.2f} {bboxes[j][2]:.2f} {bboxes[j][3]:.2f}\"\n",
    "                    )\n",
    "\n",
    "        # PredictionString을 먼저 저장하고 image_id는 그 다음에 저장\n",
    "        results.append({\n",
    "            'PredictionString': \" \".join(prediction_string),  # 한 줄에 저장\n",
    "            'image_id': f'test/{image_name}'\n",
    "        })\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv(output_csv, index=False)\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
